# 기술 스택 및 적용 기술

## 개요

Mood Manager는 생체 신호 분석, 오디오 이벤트 분류, 감정 예측, 무드 생성 등 다양한 AI 기술을 활용하여 개인화된 무드 스트림을 생성한다.

---

## 1. 통계 분석: 디스크릿 마르코프 체인 (Discrete Markov Chain)

### 기술 설명
- **용도**: 통계 분석을 위한 감정 상태 전이 확률 계산
- **특징**: 연속형(Continuous)이 아닌 분절형(Discrete) 마르코프 체인 사용
- **적용 위치**: `Web/markov/` 폴더의 Python 스크립트

### 실제 적용
- **데이터 전처리**: 일일 144개 슬롯(10분 단위) 데이터를 기반으로 감정 상태 전이 확률 계산
- **예측 모델**: `realtime_inference_many.py`에서 실시간 감정 상태 예측
- **데이터 생성**: `build_yesterday_many.py`에서 과거 데이터 기반 전이 확률 학습
- **API 연동**: `/api/ai/background-params`에서 Python 서버와 연동하여 3개 세그먼트 감정 예측

### 기술적 한계
- 전통적인 통계 기반 방법론으로, 최신 딥러닝 기법은 아니다.
- 통계 분석 및 패턴 인식 용도로 제한적으로 사용된다.

---

## 2. LLM 기반 무드 생성 기술

### 사용 모델
- **OpenAI GPT-4o-mini**: 무드 스트림 세그먼트 생성
- **Temperature**: 0.7 (창의성과 일관성의 균형)

### 주요 기능

#### 2.1 무드 스트림 생성 (`/api/moods/current/generate`)
- **입력**: 전처리된 생체 신호, 사용자 선호도, 날씨 정보, 마르코프 예측 결과
- **출력**: 10개 세그먼트(각 3분, 총 30분)의 상세 무드 정보
- **생성 항목**:
  - 무드 별명 (moodAlias)
  - 색상 (moodColor, lighting)
  - 음악 (musicID, volume, fadeIn, fadeOut)
  - 향 (scent type, name, level, interval)
  - 배경 요소 (icons, wind, animation)

#### 2.2 배경 파라미터 생성 (`/api/ai/background-params`)
- **Stream Mode**: 10개 세그먼트 전체에 대한 배경 파라미터 생성
- **Scent Mode**: 현재 세그먼트의 향/배경 요소만 재추천
- **Music Mode**: 현재 세그먼트의 음악/풍향·풍속만 재추천

#### 2.3 프롬프트 엔지니어링
- **다양성 강조**: 배경 요소와 음악의 다양성을 보장하기 위한 프롬프트를 최적화한다.
- **구조화된 출력**: JSON Schema를 통한 구조화된 응답을 보장한다.
- **컨텍스트 통합**: 사용자 선호도, 생체 신호, 외부 요인(날씨)을 통합한다.

### 기술적 특징
- **스트리밍 응답**: 대용량 세그먼트 생성 시 스트리밍으로 응답 시간을 최적화한다.
- **캐싱**: 동일 입력에 대한 중복 LLM 호출을 방지한다.
- **에러 처리**: LLM 호출 실패 시 폴백 무드 데이터를 제공한다.

---

## 3. Watch 앱 기술 (WearOS)

### 3.1 생체 신호 수집
- **Health Services API**: 심박수, HRV, 호흡수, 스트레스 지수를 실시간으로 수집한다.
- **주기적 수집**: 5분 간격으로 데이터를 수집하고 Firebase에 업로드한다.
- **Foreground Service**: `PeriodicDataService.kt`에서 백그라운드로 지속 실행한다.

### 3.2 오디오 이벤트 분류
- **AudioRecord API**: 2초 오디오를 캡처한다.
- **신호 처리**:
  - RMS/dBFS 계산으로 무음 구간을 필터링한다.
  - PCM 데이터를 WAV/Base64로 변환한다.
- **Firebase 업로드**: `AudioEventService.kt`에서 ML 서버 처리를 위한 데이터를 전송한다.

### 기술적 특징
- **배터리 최적화**: 효율적인 데이터 수집 주기를 설정한다.
- **데이터 압축**: Base64 인코딩으로 네트워크 전송을 최적화한다.
- **에러 복구**: 네트워크 오류 시 재시도 메커니즘을 사용한다.

---

## 4. ML 서버 기술 (오디오 분류)

### 사용 모델
- **Wav2Vec2 기반**: 오디오 이벤트를 분류한다 (웃음, 한숨, 부정적 감정, 노이즈).
- **ONNX 최적화**: 모델을 경량화하고 추론 속도를 향상시킨다.
- **양자화 (Quantization)**: 모델 크기 및 추론 시간을 최적화한다.

### 배포 전략
- **Docker 컨테이너화**: 일관된 실행 환경을 보장한다.
- **AWS Lambda**: 서버리스 아키텍처로 비용을 최적화한다.
- **비동기 처리**: Firestore의 `ml_processed` 플래그를 통한 작업 큐를 관리한다.

### 실제 적용
- **입력**: Firestore에 저장된 Base64 WAV 오디오 데이터이다.
- **출력**: 분류된 이벤트 타입 및 타임스탬프이다.
- **처리 흐름**: `ml_processed == 'pending'` 문서를 조회 → 처리 → `'done'`으로 업데이트한다.

---

## 5. 데이터 파이프라인

### 5.1 전처리 (`/api/preprocessing`)
- **생체 신호 정규화**: 심박수, HRV, 스트레스 지수를 정규화한다.
- **이벤트 집계**: 시간대별 오디오 이벤트 발생 빈도를 계산한다.
- **외부 데이터 통합**: 기상청 API를 통한 날씨 정보를 수집한다.
- **수면 점수 계산**: 수면 세션 기반 수면 품질 점수를 산출한다.

### 5.2 무드 스트림 생성 파이프라인
1. **전처리**: 생체 신호 + 오디오 이벤트 + 날씨 + 수면 데이터 통합
2. **마르코프 예측**: Python 서버에서 3개 세그먼트 감정 상태 예측
3. **LLM 생성**: GPT-4o-mini로 10개 세그먼트 상세 무드 정보 생성
4. **검증 및 변환**: JSON Schema 검증 및 타입 변환
5. **저장**: PostgreSQL에 무드 스트림 저장

---

## 6. 주요 기술 스택 요약

| 영역 | 기술 | 용도 |
|------|------|------|
| **통계 분석** | 디스크릿 마르코프 체인 | 감정 상태 전이 확률 계산 (통계 분석) |
| **무드 생성** | OpenAI GPT-4o-mini | 10개 세그먼트 상세 무드 정보 생성 |
| **오디오 분류** | Wav2Vec2 (ONNX) | 웃음, 한숨, 부정적 감정 분류 |
| **생체 신호** | Health Services API | 심박수, HRV, 호흡수 수집 |
| **오디오 캡처** | AudioRecord API | 2초 오디오 캡처 및 전처리 |
| **데이터베이스** | PostgreSQL (Prisma) | 사용자 데이터, 무드 스트림 저장 |
| **실시간 동기화** | Firebase Firestore | WearOS ↔ ML 서버 ↔ Web 앱 데이터 동기화 |
| **배포** | AWS Lambda | ML 서버 서버리스 배포 |
| **웹 프레임워크** | Next.js 15 | 서버 사이드 렌더링 및 API 라우트 |

---

## 참고사항

- **마르코프 체인**: 전통적인 통계 기반 방법론으로, 최신 딥러닝 기법은 아니다. 통계 분석 및 패턴 인식 용도로 제한적으로 사용된다.
- **LLM 기반 생성**: 실제 서비스에서 무드 스트림의 핵심 생성 엔진으로 사용된다.
- **ML 오디오 분류**: 실시간 오디오 이벤트 분류를 위한 경량화된 모델을 사용한다.

